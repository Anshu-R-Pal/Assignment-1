#Evaluation Function and Training Model

def eval_model(model, data_loader, device, criterion=None):
    model.eval()
    correct = 0
    total = 0
    running_loss = 0.0
    with torch.no_grad():
        for inputs, targets in data_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            if criterion:
                loss = criterion(outputs, targets)
                running_loss += loss.item()*inputs.size(0)
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
    acc = 100.*correct/total
    avg_loss = running_loss/total if criterion else 0
    return acc, avg_loss

#Training Model and Login with Wand B

def train(model, train_loader, val_loader, test_loader, device, optimizer, criterion, epochs, wandb_run=None):
    best_val_acc = 0
    for epoch in range(epochs):
        model.train()
        running_loss = 0.0

        for x, y in train_loader:
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()
            outputs = model(x)
            loss = criterion(outputs, y)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

        train_loss = running_loss / len(train_loader)
        train_acc, train_loss = eval_model(model, train_loader, device, criterion)

        # Compute validation loss & accuracy
        model.eval()
        val_loss = 0.0
        correct = 0
        total = 0
        with torch.no_grad():
            for x, y in val_loader:
                x, y = x.to(device), y.to(device)
                outputs = model(x)
                loss = criterion(outputs, y)
                val_loss += loss.item()
                _, predicted = outputs.max(1)
                total += y.size(0)
                correct += predicted.eq(y).sum().item()
        val_loss /= len(val_loader)
        val_acc = 100. * correct / total

        # Compute test accuracy
        test_acc, _ = eval_model(model, test_loader, device)

        # Print to Colab output
        print(f"Epoch {epoch+1}/{epochs} | "
              f"Train Loss: {train_loss:.4f} | "
              f"Train Acc: {train_acc:.2f}% | "
              f"Val Loss: {val_loss:.4f} | "
              f"Val Acc: {val_acc:.2f}% | "
              f"Test Acc: {test_acc:.2f}%")

        # Log to W&B
        if wandb_run:
            wandb_run.log({
                "epoch": epoch + 1,
                "train_loss": train_loss,
                "train_acc": train_acc,
                "val_loss": val_loss,
                "val_acc": val_acc,
                "test_acc": test_acc
            })

        # Save best model
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            os.makedirs("saved_models", exist_ok=True)
            torch.save(model.state_dict(), "saved_models/best_model.pth")

    return best_val_acc

